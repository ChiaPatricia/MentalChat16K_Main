Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 24.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:54<00:00, 27.21s/it]
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:22<00:22, 22.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:30<00:00, 14.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:30<00:00, 15.49s/it]
This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (4096). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:10<03:12, 10.68s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:21<03:04, 10.87s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:32<02:51, 10.69s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:42<02:37, 10.51s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:53<02:28, 10.61s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [01:03<02:17, 10.62s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [01:14<02:05, 10.49s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [01:24<01:54, 10.43s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [01:35<01:45, 10.58s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [01:45<01:33, 10.39s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [01:55<01:23, 10.47s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [02:06<01:13, 10.56s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [02:17<01:03, 10.58s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [02:27<00:52, 10.46s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [02:38<00:42, 10.54s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [02:48<00:31, 10.53s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [02:58<00:20, 10.41s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [03:09<00:10, 10.46s/it]Loading checkpoint shards: 100%|██████████| 19/19 [03:18<00:00, 10.01s/it]Loading checkpoint shards: 100%|██████████| 19/19 [03:18<00:00, 10.44s/it]
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:05<01:44,  5.83s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:11<01:41,  5.96s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:17<01:35,  5.99s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:23<01:29,  5.96s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:29<01:24,  6.01s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:35<01:18,  6.03s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:41<01:12,  6.01s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:47<01:06,  6.02s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:54<01:00,  6.02s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:59<00:54,  6.01s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [01:06<00:48,  6.02s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [01:12<00:42,  6.02s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [01:14<00:43,  6.23s/it]
Traceback (most recent call last):
  File "/gpfs/fs001/cbica/home/xjia/qlora/examples/qlora_models_generate.py", line 128, in <module>
    model = AutoModelForCausalLM.from_pretrained(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 566, in from_pretrained
    return model_class.from_pretrained(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3706, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/modeling_utils.py", line 4116, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/modeling_utils.py", line 786, in _load_state_dict_into_meta_model
    set_module_quantized_tensor_to_device(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/integrations/bitsandbytes.py", line 98, in set_module_quantized_tensor_to_device
    new_value = bnb.nn.Params4bit(new_value, requires_grad=False, **kwargs).to(device)
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/bitsandbytes/nn/modules.py", line 179, in to
    return self.cuda(device)
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/bitsandbytes/nn/modules.py", line 157, in cuda
    w_4bit, quant_state = bnb.functional.quantize_4bit(w, blocksize=self.blocksize, compress_statistics=self.compress_statistics, quant_type=self.quant_type)
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/bitsandbytes/functional.py", line 816, in quantize_4bit
    out = torch.zeros(((n+1)//2, 1), dtype=torch.uint8, device=A.device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 28.00 MiB (GPU 0; 44.56 GiB total capacity; 42.71 GiB already allocated; 14.31 MiB free; 43.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
