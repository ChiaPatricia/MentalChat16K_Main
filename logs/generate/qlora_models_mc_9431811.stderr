Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:10<01:14, 10.66s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:16<00:48,  8.06s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:23<00:35,  7.19s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:29<00:26,  6.74s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:34<00:19,  6.40s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:41<00:12,  6.34s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:46<00:06,  6.08s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:48<00:00,  4.82s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:48<00:00,  6.10s/it]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:02<00:16,  2.41s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:05<00:15,  2.53s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:07<00:13,  2.61s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:10<00:10,  2.63s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:13<00:07,  2.65s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:15<00:05,  2.64s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:18<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:19<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:19<00:00,  2.42s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:41<00:41, 41.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 25.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:55<00:00, 27.93s/it]
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:32<00:32, 32.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:44<00:00, 20.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:45<00:00, 22.96s/it]
