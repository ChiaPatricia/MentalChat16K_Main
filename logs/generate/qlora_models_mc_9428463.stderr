Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.33s/it]
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:35<00:00, 16.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:35<00:00, 17.70s/it]
Traceback (most recent call last):
  File "/gpfs/fs001/cbica/home/xjia/qlora/examples/qlora_models_mc_generate.py", line 134, in <module>
    base_response, base_answer = generate(base_model, question["turns"][0], prompt)
  File "/gpfs/fs001/cbica/home/xjia/qlora/examples/qlora_models_mc_generate.py", line 46, in generate
    mc_answer = re.search(r'Correct Answer: (\w)', text[1]).group(1)
AttributeError: 'NoneType' object has no attribute 'group'
