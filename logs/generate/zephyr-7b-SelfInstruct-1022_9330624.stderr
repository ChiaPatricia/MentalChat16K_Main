Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]Downloading shards:  25%|██▌       | 2/8 [00:00<00:00, 18.37it/s]Downloading shards:  50%|█████     | 4/8 [00:00<00:00,  8.46it/s]Downloading shards:  88%|████████▊ | 7/8 [00:00<00:00, 12.72it/s]Downloading shards: 100%|██████████| 8/8 [00:00<00:00, 12.75it/s]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:10<01:13, 10.43s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:16<00:47,  7.93s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:22<00:35,  7.11s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:28<00:26,  6.62s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:34<00:19,  6.40s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:40<00:12,  6.26s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:46<00:06,  6.09s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:48<00:00,  4.92s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:48<00:00,  6.10s/it]
Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]Loading checkpoint shards:  12%|█▎        | 1/8 [00:01<00:13,  1.96s/it]Loading checkpoint shards:  25%|██▌       | 2/8 [00:04<00:12,  2.04s/it]Loading checkpoint shards:  38%|███▊      | 3/8 [00:06<00:10,  2.07s/it]Loading checkpoint shards:  50%|█████     | 4/8 [00:08<00:08,  2.07s/it]Loading checkpoint shards:  62%|██████▎   | 5/8 [00:10<00:06,  2.09s/it]Loading checkpoint shards:  75%|███████▌  | 6/8 [00:12<00:04,  2.08s/it]Loading checkpoint shards:  88%|████████▊ | 7/8 [00:14<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:15<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 8/8 [00:15<00:00,  1.91s/it]
Traceback (most recent call last):
  File "/gpfs/fs001/cbica/home/xjia/qlora/examples/zephyr_generate.py", line 144, in <module>
    pt, base_response = generate(base_model, test_df['instruction'][i], test_df["input"][i], prompt)
  File "/gpfs/fs001/cbica/home/xjia/qlora/examples/zephyr_generate.py", line 118, in generate
    outputs = model.generate(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/utils.py", line 1693, in generate
    return self.sample(
  File "/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages/transformers/generation/utils.py", line 2816, in sample
    raise ValueError("If `eos_token_id` is defined, make sure that `pad_token_id` is defined.")
ValueError: If `eos_token_id` is defined, make sure that `pad_token_id` is defined.
