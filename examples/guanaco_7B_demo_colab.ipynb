{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lwSKH5kZsLP5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gradio in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (3.35.2)\n",
            "Requirement already satisfied: aiofiles in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (23.1.0)\n",
            "Requirement already satisfied: aiohttp in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (3.8.4)\n",
            "Requirement already satisfied: altair>=4.2.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (5.0.1)\n",
            "Requirement already satisfied: fastapi in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.98.0)\n",
            "Requirement already satisfied: ffmpy in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: gradio-client>=0.2.7 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.2.7)\n",
            "Requirement already satisfied: httpx in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.24.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.17.3)\n",
            "Requirement already satisfied: jinja2 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: mdit-py-plugins<=0.3.3 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: numpy in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (1.25.0)\n",
            "Requirement already satisfied: orjson in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (3.9.1)\n",
            "Requirement already satisfied: pandas in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: pillow in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (9.5.0)\n",
            "Requirement already satisfied: pydantic in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (1.10.9)\n",
            "Requirement already satisfied: pydub in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.15.1)\n",
            "Requirement already satisfied: python-multipart in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.0.6)\n",
            "Requirement already satisfied: pyyaml in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: requests in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.31.0)\n",
            "Requirement already satisfied: semantic-version in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (0.22.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio) (11.0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.17.3)\n",
            "Requirement already satisfied: toolz in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (0.12.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from altair>=4.2.0->gradio) (4.6.3)\n",
            "Requirement already satisfied: fsspec in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio-client>=0.2.7->gradio) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from gradio-client>=0.2.7->gradio) (23.1)\n",
            "Requirement already satisfied: filelock in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from huggingface-hub>=0.14.0->gradio) (3.12.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from huggingface-hub>=0.14.0->gradio) (4.65.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from markdown-it-py[linkify]>=2.0.0->gradio) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from pandas->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from pandas->gradio) (2023.3)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from pandas->gradio) (2023.3)\n",
            "Requirement already satisfied: click>=7.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from uvicorn>=0.14.0->gradio) (0.14.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from fastapi->gradio) (0.27.0)\n",
            "Requirement already satisfied: certifi in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from httpx->gradio) (2023.5.7)\n",
            "Requirement already satisfied: httpcore<0.18.0,>=0.15.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from httpx->gradio) (0.17.2)\n",
            "Requirement already satisfied: idna in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from httpx->gradio) (3.4)\n",
            "Requirement already satisfied: sniffio in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from httpx->gradio) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (3.1.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from matplotlib->gradio) (5.12.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from requests->gradio) (2.0.3)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio) (3.7.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib->gradio) (3.15.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from jsonschema>=3.0->altair>=4.2.0->gradio) (0.19.3)\n",
            "Requirement already satisfied: uc-micro-py in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->gradio) (1.16.0)\n",
            "Requirement already satisfied: exceptiongroup in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio) (1.1.1)\n",
            "Requirement already satisfied: sentencepiece in /gpfs/fs001/cbica/home/xjia/.conda/envs/textlearning/lib/python3.9/site-packages (0.1.99)\n"
          ]
        }
      ],
      "source": [
        "# Install latest bitsandbytes & transformers, accelerate from source\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "# Other requirements for the demo\n",
        "!pip install gradio\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QK51MtdsMLu"
      },
      "outputs": [],
      "source": [
        "# Load the model.\n",
        "# Note: It can take a while to download LLaMA and add the adapter modules.\n",
        "# You can also use the 13B model by loading in 4bits.\n",
        "\n",
        "import torch\n",
        "from peft import PeftModel    \n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, LlamaTokenizer, StoppingCriteria, StoppingCriteriaList, TextIteratorStreamer\n",
        "\n",
        "model_name = \"decapoda-research/llama-7b-hf\"\n",
        "adapters_name = 'timdettmers/guanaco-7b'\n",
        "\n",
        "print(f\"Starting to load the model {model_name} into memory\")\n",
        "\n",
        "m = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    #load_in_4bit=True,\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map={\"\": 0}\n",
        ")\n",
        "m = PeftModel.from_pretrained(m, adapters_name)\n",
        "m = m.merge_and_unload()\n",
        "tok = LlamaTokenizer.from_pretrained(model_name)\n",
        "tok.bos_token_id = 1\n",
        "\n",
        "stop_token_ids = [0]\n",
        "\n",
        "print(f\"Successfully loaded the model {model_name} into memory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aklTR-es2bma"
      },
      "outputs": [],
      "source": [
        "# Setup the gradio Demo.\n",
        "\n",
        "import datetime\n",
        "import os\n",
        "from threading import Event, Thread\n",
        "from uuid import uuid4\n",
        "\n",
        "import gradio as gr\n",
        "import requests\n",
        "\n",
        "max_new_tokens = 1536\n",
        "start_message = \"\"\"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n",
        "\n",
        "class StopOnTokens(StoppingCriteria):\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop_id in stop_token_ids:\n",
        "            if input_ids[0][-1] == stop_id:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "\n",
        "def convert_history_to_text(history):\n",
        "    text = start_message + \"\".join(\n",
        "        [\n",
        "            \"\".join(\n",
        "                [\n",
        "                    f\"### Human: {item[0]}\\n\",\n",
        "                    f\"### Assistant: {item[1]}\\n\",\n",
        "                ]\n",
        "            )\n",
        "            for item in history[:-1]\n",
        "        ]\n",
        "    )\n",
        "    text += \"\".join(\n",
        "        [\n",
        "            \"\".join(\n",
        "                [\n",
        "                    f\"### Human: {history[-1][0]}\\n\",\n",
        "                    f\"### Assistant: {history[-1][1]}\\n\",\n",
        "                ]\n",
        "            )\n",
        "        ]\n",
        "    )\n",
        "    return text\n",
        "\n",
        "\n",
        "def log_conversation(conversation_id, history, messages, generate_kwargs):\n",
        "    logging_url = os.getenv(\"LOGGING_URL\", None)\n",
        "    if logging_url is None:\n",
        "        return\n",
        "\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
        "\n",
        "    data = {\n",
        "        \"conversation_id\": conversation_id,\n",
        "        \"timestamp\": timestamp,\n",
        "        \"history\": history,\n",
        "        \"messages\": messages,\n",
        "        \"generate_kwargs\": generate_kwargs,\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        requests.post(logging_url, json=data)\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error logging conversation: {e}\")\n",
        "\n",
        "\n",
        "def user(message, history):\n",
        "    # Append the user's message to the conversation history\n",
        "    return \"\", history + [[message, \"\"]]\n",
        "\n",
        "\n",
        "def bot(history, temperature, top_p, top_k, repetition_penalty, conversation_id):\n",
        "    print(f\"history: {history}\")\n",
        "    # Initialize a StopOnTokens object\n",
        "    stop = StopOnTokens()\n",
        "\n",
        "    # Construct the input message string for the model by concatenating the current system message and conversation history\n",
        "    messages = convert_history_to_text(history)\n",
        "\n",
        "    # Tokenize the messages string\n",
        "    input_ids = tok(messages, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(m.device)\n",
        "    streamer = TextIteratorStreamer(tok, timeout=10.0, skip_prompt=True, skip_special_tokens=True)\n",
        "    generate_kwargs = dict(\n",
        "        input_ids=input_ids,\n",
        "        max_new_tokens=max_new_tokens,\n",
        "        temperature=temperature,\n",
        "        do_sample=temperature > 0.0,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        repetition_penalty=repetition_penalty,\n",
        "        streamer=streamer,\n",
        "        stopping_criteria=StoppingCriteriaList([stop]),\n",
        "    )\n",
        "\n",
        "    stream_complete = Event()\n",
        "\n",
        "    def generate_and_signal_complete():\n",
        "        m.generate(**generate_kwargs)\n",
        "        stream_complete.set()\n",
        "\n",
        "    def log_after_stream_complete():\n",
        "        stream_complete.wait()\n",
        "        log_conversation(\n",
        "            conversation_id,\n",
        "            history,\n",
        "            messages,\n",
        "            {\n",
        "                \"top_k\": top_k,\n",
        "                \"top_p\": top_p,\n",
        "                \"temperature\": temperature,\n",
        "                \"repetition_penalty\": repetition_penalty,\n",
        "            },\n",
        "        )\n",
        "\n",
        "    t1 = Thread(target=generate_and_signal_complete)\n",
        "    t1.start()\n",
        "\n",
        "    t2 = Thread(target=log_after_stream_complete)\n",
        "    t2.start()\n",
        "\n",
        "    # Initialize an empty string to store the generated text\n",
        "    partial_text = \"\"\n",
        "    for new_text in streamer:\n",
        "        partial_text += new_text\n",
        "        history[-1][1] = partial_text\n",
        "        yield history\n",
        "\n",
        "\n",
        "def get_uuid():\n",
        "    return str(uuid4())\n",
        "\n",
        "\n",
        "with gr.Blocks(\n",
        "    theme=gr.themes.Soft(),\n",
        "    css=\".disclaimer {font-variant-caps: all-small-caps;}\",\n",
        ") as demo:\n",
        "    conversation_id = gr.State(get_uuid)\n",
        "    gr.Markdown(\n",
        "        \"\"\"<h1><center>Guanaco Demo</center></h1>\n",
        "\"\"\"\n",
        "    )\n",
        "    chatbot = gr.Chatbot().style(height=500)\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            msg = gr.Textbox(\n",
        "                label=\"Chat Message Box\",\n",
        "                placeholder=\"Chat Message Box\",\n",
        "                show_label=False,\n",
        "            ).style(container=False)\n",
        "        with gr.Column():\n",
        "            with gr.Row():\n",
        "                submit = gr.Button(\"Submit\")\n",
        "                stop = gr.Button(\"Stop\")\n",
        "                clear = gr.Button(\"Clear\")\n",
        "    with gr.Row():\n",
        "        with gr.Accordion(\"Advanced Options:\", open=False):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        temperature = gr.Slider(\n",
        "                            label=\"Temperature\",\n",
        "                            value=0.7,\n",
        "                            minimum=0.0,\n",
        "                            maximum=1.0,\n",
        "                            step=0.1,\n",
        "                            interactive=True,\n",
        "                            info=\"Higher values produce more diverse outputs\",\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        top_p = gr.Slider(\n",
        "                            label=\"Top-p (nucleus sampling)\",\n",
        "                            value=0.9,\n",
        "                            minimum=0.0,\n",
        "                            maximum=1,\n",
        "                            step=0.01,\n",
        "                            interactive=True,\n",
        "                            info=(\n",
        "                                \"Sample from the smallest possible set of tokens whose cumulative probability \"\n",
        "                                \"exceeds top_p. Set to 1 to disable and sample from all tokens.\"\n",
        "                            ),\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        top_k = gr.Slider(\n",
        "                            label=\"Top-k\",\n",
        "                            value=0,\n",
        "                            minimum=0.0,\n",
        "                            maximum=200,\n",
        "                            step=1,\n",
        "                            interactive=True,\n",
        "                            info=\"Sample from a shortlist of top-k tokens — 0 to disable and sample from all tokens.\",\n",
        "                        )\n",
        "                with gr.Column():\n",
        "                    with gr.Row():\n",
        "                        repetition_penalty = gr.Slider(\n",
        "                            label=\"Repetition Penalty\",\n",
        "                            value=1.0,\n",
        "                            minimum=1.0,\n",
        "                            maximum=2.0,\n",
        "                            step=0.1,\n",
        "                            interactive=True,\n",
        "                            info=\"Penalize repetition — 1.0 to disable.\",\n",
        "                        )\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\n",
        "            \"Disclaimer: The model can produce factually incorrect output, and should not be relied on to produce \"\n",
        "            \"factually accurate information. The model was trained on various public datasets; while great efforts \"\n",
        "            \"have been taken to clean the pretraining data, it is possible that this model could generate lewd, \"\n",
        "            \"biased, or otherwise offensive outputs.\",\n",
        "            elem_classes=[\"disclaimer\"],\n",
        "        )\n",
        "    with gr.Row():\n",
        "        gr.Markdown(\n",
        "            \"[Privacy policy](https://gist.github.com/samhavens/c29c68cdcd420a9aa0202d0839876dac)\",\n",
        "            elem_classes=[\"disclaimer\"],\n",
        "        )\n",
        "\n",
        "    submit_event = msg.submit(\n",
        "        fn=user,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[msg, chatbot],\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=bot,\n",
        "        inputs=[\n",
        "            chatbot,\n",
        "            temperature,\n",
        "            top_p,\n",
        "            top_k,\n",
        "            repetition_penalty,\n",
        "            conversation_id,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        queue=True,\n",
        "    )\n",
        "    submit_click_event = submit.click(\n",
        "        fn=user,\n",
        "        inputs=[msg, chatbot],\n",
        "        outputs=[msg, chatbot],\n",
        "        queue=False,\n",
        "    ).then(\n",
        "        fn=bot,\n",
        "        inputs=[\n",
        "            chatbot,\n",
        "            temperature,\n",
        "            top_p,\n",
        "            top_k,\n",
        "            repetition_penalty,\n",
        "            conversation_id,\n",
        "        ],\n",
        "        outputs=chatbot,\n",
        "        queue=True,\n",
        "    )\n",
        "    stop.click(\n",
        "        fn=None,\n",
        "        inputs=None,\n",
        "        outputs=None,\n",
        "        cancels=[submit_event, submit_click_event],\n",
        "        queue=False,\n",
        "    )\n",
        "    clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.queue(max_size=128, concurrency_count=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0nzyqUks49E"
      },
      "outputs": [],
      "source": [
        "# Launch your Guanaco Demo!\n",
        "demo.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3Iq8VC6s7I5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
